spring.application.name=McpServerRestAPI
server.port=8088
spring.ai.mcp.server.protocol=STREAMABLE
#spring.ai.mcp.server.stdio=true
spring.ai.mcp.server.type=SYNC
spring.ai.mcp.server.sse-endpoint=/sse
spring.ai.mcp.server.sse-message-endpoint=/mcp/message

logging.level.org.springframework.ai.mcp=DEBUG
logging.level.io.modelcontextprotocol=DEBUG

# ===== API base URL =====
api.base.url=<url_here>

# Activate this profile when you want insecure SSL (dev only)
# --spring.profiles.active=insecure-ssl+

# ===== OAuth2 token endpoint config =====
security.oauth2.token-uri=<ri_here>
security.oauth2.client-id=<id>
security.oauth2.client-secret=<secret>

# Choose the grant you actually use: password or client_credentials
security.oauth2.grant-type=client_credentials
security.oauth2.username=<user>
security.oauth2.password=<pass>

# If you use client_credentials instead, set:
# security.oauth2.grant-type=client_credentials
# (username/password are ignored for client_credentials)

#security.oauth2.scope=read write                  # adjust or leave blank
#security.oauth2.basic-auth-for-client=TRUE        # send client credentials via Authorization: Basic


# Optional logging (helps diagnose 404)
logging.level.org.springframework.web.client.RestClient=DEBUG
logging.level.org.apache.hc.client5.http=DEBUG
logging.level.org.apache.hc.client5.http.wire=ERROR

spring.ai.openai.api-key=<key_here>
spring.ai.openai.chat.model=<model_here>


spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=tinyllama        # or llama3:8b, qwen2.5:7b, etc.

